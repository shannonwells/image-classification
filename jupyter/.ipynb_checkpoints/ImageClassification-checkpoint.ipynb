{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd6a144-56b5-43f6-9b77-1a1591c96a03",
   "metadata": {},
   "source": [
    "# Image Classification w/ Keras\n",
    "---\n",
    "In this project we attempt to classify if a image is a painting or a photograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281623ce-60e6-4ad5-9af9-963e1ed7bef3",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7716ede-aaa0-41a0-845d-ac3e07c75d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774274f-1755-43d5-9e64-525829084e99",
   "metadata": {},
   "source": [
    "### Setup our experiment variables\n",
    "\n",
    "*Note*: We don't have consistent image sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89d099af-863a-4057-80a1-46dc143f2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 600, 600\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/test'\n",
    "nb_train_samples =200 \n",
    "nb_validation_samples = 50\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663983f5-2c68-4e27-8400-32ae97c2ab4f",
   "metadata": {},
   "source": [
    "Here we check the data format (RGB channel) so we can feed to model accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c59e261-af19-4061-be38-9448cafe590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769942a-41d6-485a-8bdd-05ab8aa53b47",
   "metadata": {},
   "source": [
    "### Create or learning model\n",
    "\n",
    "For this experiment we are using a [Sequential model](https://keras.io/api/models/sequential/) which groups linear layers into our model.\n",
    "\n",
    "#### Definitions:\n",
    "**Conv2D** is the layer to convolve the image into multiple images\n",
    "\n",
    "**Activation** is the activation function.\n",
    "\n",
    "**MaxPooling2D** is used to max pool the value from the given size matrix and same is used for the next 2 layers. then, Flatten is used to flatten the dimensions of the image obtained after convolving it.\n",
    "\n",
    "**Dense** is used to make this a fully connected model and is the hidden layer.\n",
    "\n",
    "**Dropout** is used to avoid overfitting on the dataset.\n",
    "\n",
    "**Dense** is the output layer contains only one neuron which decide to which category image belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a548103-8e77-4e3c-941f-ceccbe8856a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d06e4-46fe-43bc-869e-4b93f751c8fb",
   "metadata": {},
   "source": [
    "**ImageDataGenerator** that rescales the image, applies shear in some range, zooms the image and does horizontal flipping with the image. This ImageDataGenerator includes all possible orientation of the image.\n",
    "\n",
    "**train_datagen.flow_from_directory** is the function that is used to prepare data from the train_dataset directory Target_size specifies the target size of the image.\n",
    "\n",
    "**test_datagen.flow_from_directory** is used to prepare test data for the model and all is similar as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab116b76-e37d-4a7d-b353-4f518ec166e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8575 images belonging to 2 classes.\n",
      "Found 476 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "  \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "  \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "  \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80557-137e-47b7-b3b1-61f3761a432d",
   "metadata": {},
   "source": [
    "**fit_generator** is used to fit the data into the model made above, other factors used are steps_per_epochs tells us about the number of times the model will execute for the training data.\n",
    "\n",
    "**epochs** tells us the number of times model will be trained in forward and backward pass.\n",
    "\n",
    "**validation_data** is used to feed the validation/test data into the model.\n",
    "\n",
    "**validation_steps** denotes the number of validation/test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced98b46-95ce-4841-9765-0af48c42a4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 147s 2s/step - loss: 0.9145 - accuracy: 0.7709 - val_loss: 9.6290 - val_accuracy: 0.0729\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 137s 2s/step - loss: 0.3295 - accuracy: 0.8881 - val_loss: -0.0286 - val_accuracy: 0.1667\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 143s 2s/step - loss: 0.2814 - accuracy: 0.9234 - val_loss: 0.4783 - val_accuracy: 0.2083\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 135s 2s/step - loss: 0.2467 - accuracy: 0.9264 - val_loss: 1.1874 - val_accuracy: 0.0833\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 136s 2s/step - loss: 0.2635 - accuracy: 0.9304 - val_loss: 5.0168 - val_accuracy: 0.0435\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 138s 2s/step - loss: 0.2950 - accuracy: 0.9173 - val_loss: -1.9612 - val_accuracy: 0.3021\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 137s 2s/step - loss: 0.2418 - accuracy: 0.9244 - val_loss: 1.3230 - val_accuracy: 0.0938\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 135s 2s/step - loss: 0.2335 - accuracy: 0.9153 - val_loss: 2.5767 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 135s 2s/step - loss: 0.2042 - accuracy: 0.9446 - val_loss: -0.6122 - val_accuracy: 0.1250\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 134s 2s/step - loss: 0.2386 - accuracy: 0.9234 - val_loss: 5.8147 - val_accuracy: 0.0652\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('model_saved.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fd71e-8d11-4c5f-b6a1-4231bed876d7",
   "metadata": {},
   "source": [
    "### Sources\n",
    "---\n",
    "\n",
    "Sourced from https://www.geeksforgeeks.org/python-image-classification-using-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
